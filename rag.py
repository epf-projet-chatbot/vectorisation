from pymongo import MongoClient
from pymongo.errors import ServerSelectionTimeoutError, OperationFailure
from os import getenv
import os
from sklearn.neighbors import NearestNeighbors
from embedder import get_embedding
from mongo import init_connection, client, db, collection
from config import config

def make_vector(user_request:str):
    """
    Transforme la requ√™te utilisateur en vecteur.
    
    Args:
        user_request: La requ√™te de l'utilisateur √† transformer en vecteur.
    
    Returns:
        Un vecteur repr√©sentant la requ√™te de l'utilisateur.
    """
    
    return get_embedding(user_request)

def k_context_vectors(request_vector, k:int):
    """
    R√©cup√®re les k vecteurs les plus proches du vecteur de requ√™te dans la collection MongoDB.
    
    Args:
        request_vector: Le vecteur de requ√™te pour la recherche.
        k: Le nombre de vecteurs √† r√©cup√©rer.
    
    Returns:
        Une liste du contenu des k documents les plus proches.
    """
    # S'assurer que la connexion est initialis√©e
    init_connection()
    
    # V√©rifier que la collection est disponible
    if collection is None:
        raise ConnectionError("Collection MongoDB non initialis√©e")
    
    # R√©cup√©rer tous les vecteurs et leurs m√©tadonn√©es
    vectors = list(collection.find())
    
    # Afficher des informations de debug avec les bons noms de base/collection
    database_name = config.get_database_name()
    collection_name = config.get_collection_name()
    mode_info = "TEST" if config.test_mode else "PROD"
    
    print(f"üìä [{mode_info}] {len(vectors)} vecteurs dans '{database_name}.{collection_name}'")
    
    if not vectors:
        print("‚ö†Ô∏è  Aucun vecteur trouv√© dans la collection.")
        return []
    
    # Extraire les vecteurs du champ embedding
    vector_data = [v['embedding'] for v in vectors]
    
    # Utiliser NearestNeighbors pour trouver les k plus proches voisins
    # S'assurer que k ne d√©passe pas le nombre de vecteurs disponibles
    effective_k = min(k, len(vectors))
    nbrs = NearestNeighbors(n_neighbors=effective_k, algorithm='auto').fit(vector_data)
    distances, indices = nbrs.kneighbors([request_vector])
    
    # R√©cup√©rer le contexte associ√© √† ces vecteurs
    closest_vectors = [vectors[i] for i in indices[0]]
    
    # Trier par pertinence (distance croissante) et ajouter les distances
    vector_with_distance = list(zip(closest_vectors, distances[0]))
    vector_with_distance.sort(key=lambda x: x[1])  # Trier par distance croissante
    
    # Extraire le contenu et filtrer les doublons
    context_texts = []
    seen_content = set()
    
    for vector, distance in vector_with_distance:
        content = vector['content']
        # √âviter les doublons de contenu
        content_hash = hash(content[:100])  # Hash des 100 premiers caract√®res
        if content_hash not in seen_content:
            seen_content.add(content_hash)
            context_texts.append(content)
    
    print(f"‚úÖ {len(context_texts)} chunks de contexte r√©cup√©r√©s (doublons supprim√©s)")
    
    return context_texts

def k_context_vectors_smart(request_vector, k: int, prioritize_metadata: bool = True):
    """
    Version am√©lior√©e qui utilise les m√©tadonn√©es pour prioriser les chunks pertinents
    
    Args:
        request_vector: Le vecteur de requ√™te pour la recherche.
        k: Le nombre de vecteurs √† r√©cup√©rer.
        prioritize_metadata: Si True, privil√©gie les chunks avec des m√©tadonn√©es importantes.
    
    Returns:
        Une liste du contenu des k documents les plus proches, optimis√©e par m√©tadonn√©es.
    """
    # S'assurer que la connexion est initialis√©e
    init_connection()
    
    # V√©rifier que la collection est disponible
    if collection is None:
        raise ConnectionError("Collection MongoDB non initialis√©e")
    
    # R√©cup√©rer tous les vecteurs et leurs m√©tadonn√©es
    vectors = list(collection.find())
    
    # Afficher des informations de debug
    database_name = config.get_database_name()
    collection_name = config.get_collection_name()
    mode_info = "TEST" if config.test_mode else "PROD"
    
    print(f"üìä [{mode_info}] {len(vectors)} vecteurs dans '{database_name}.{collection_name}'")
    
    if not vectors:
        print("‚ö†Ô∏è  Aucun vecteur trouv√© dans la collection.")
        return []
    
    # Extraire les vecteurs du champ embedding
    vector_data = [v['embedding'] for v in vectors]
    
    # Utiliser NearestNeighbors pour trouver plus de voisins que n√©cessaire
    search_k = min(k * 3, len(vectors))  # Chercher 3x plus pour avoir du choix
    nbrs = NearestNeighbors(n_neighbors=search_k, algorithm='auto').fit(vector_data)
    distances, indices = nbrs.kneighbors([request_vector])
    
    # R√©cup√©rer les vecteurs candidats avec leurs distances
    candidates = []
    for i, distance in zip(indices[0], distances[0]):
        vector = vectors[i]
        score = 1.0 / (1.0 + distance)  # Convertir distance en score (plus haut = mieux)
        
        # Bonus pour les m√©tadonn√©es importantes si activ√©
        if prioritize_metadata and 'metadata' in vector:
            metadata = vector['metadata']
            if metadata.get('has_numbers', False):
                score *= 1.2  # Boost pour les chunks avec des nombres
            if metadata.get('has_currency', False):
                score *= 1.3  # Boost pour les chunks avec des devises
            if metadata.get('has_dates', False):
                score *= 1.1  # Boost pour les chunks avec des dates
        
        candidates.append((vector, score, distance))
    
    # Trier par score d√©croissant
    candidates.sort(key=lambda x: x[1], reverse=True)
    
    # S√©lectionner les k meilleurs en √©vitant les doublons
    selected_chunks = []
    seen_content = set()
    
    for vector, score, distance in candidates:
        if len(selected_chunks) >= k:
            break
            
        content = vector['content']
        content_hash = hash(content[:100])  # Hash des 100 premiers caract√®res
        
        if content_hash not in seen_content:
            seen_content.add(content_hash)
            selected_chunks.append(content)
    
    print(f"‚úÖ {len(selected_chunks)} chunks de contexte r√©cup√©r√©s (avec priorit√© m√©tadonn√©es: {prioritize_metadata})")
    
    return selected_chunks