"""
Pipeline complÃ¨te de traitement des documents :
1. Chargement des documents
2. DÃ©coupage en chunks
3. GÃ©nÃ©ration des embeddings
4. Insertion dans MongoDB
"""

import os
import argparse
from typing import Optional

from loader import load_all_documents
from chunker import process_documents_chunks
from embedder import process_chunks_embeddings
from mongo import insert_chunks_batch, clear_collection, get_collection_stats

def run_pipeline(chunk_size: int = 1000, overlap: int = 200, clear_db: bool = False):
    """
    ExÃ©cute la pipeline complÃ¨te de traitement des documents
    
    Args:
        chunk_size: Taille maximale des chunks en caractÃ¨res
        overlap: Chevauchement entre les chunks
        clear_db: Si True, vide la base de donnÃ©es avant l'insertion
    """
    print("=" * 60)
    print("ğŸš€ DÃ‰MARRAGE DE LA PIPELINE DE VECTORISATION")
    print("=" * 60)
    
    try:
        # Optionnel : vider la base de donnÃ©es
        if clear_db:
            print("\nğŸ—‘ï¸  Nettoyage de la base de donnÃ©es...")
            clear_collection()
        
        # Ã‰tape 1: Chargement des documents
        print("\nğŸ“‚ Ã‰TAPE 1: Chargement des documents")
        print("-" * 40)
        documents = load_all_documents()
        
        if not documents:
            print("âŒ Aucun document trouvÃ©. ArrÃªt de la pipeline.")
            return
        
        print(f"âœ… {len(documents)} documents chargÃ©s avec succÃ¨s")
        
        # Ã‰tape 2: DÃ©coupage en chunks
        print(f"\nâœ‚ï¸  Ã‰TAPE 2: DÃ©coupage en chunks")
        print("-" * 40)
        print(f"ParamÃ¨tres: chunk_size={chunk_size}, overlap={overlap}")
        chunks = process_documents_chunks(documents, chunk_size, overlap)
        
        if not chunks:
            print("âŒ Aucun chunk crÃ©Ã©. ArrÃªt de la pipeline.")
            return
        
        # Ã‰tape 3: GÃ©nÃ©ration des embeddings
        print(f"\nğŸ§  Ã‰TAPE 3: GÃ©nÃ©ration des embeddings")
        print("-" * 40)
        chunks_with_embeddings = process_chunks_embeddings(chunks)
        
        # Ã‰tape 4: Insertion dans MongoDB
        print(f"\nğŸ’¾ Ã‰TAPE 4: Insertion dans MongoDB")
        print("-" * 40)
        inserted_ids = insert_chunks_batch(chunks_with_embeddings)
        
        # Statistiques finales
        print(f"\nğŸ“Š STATISTIQUES FINALES")
        print("-" * 40)
        print(f"Documents traitÃ©s: {len(documents)}")
        print(f"Chunks crÃ©Ã©s: {len(chunks)}")
        print(f"Embeddings gÃ©nÃ©rÃ©s: {len(chunks_with_embeddings)}")
        print(f"Documents insÃ©rÃ©s en DB: {len(inserted_ids)}")
        
        get_collection_stats()
        
        print("\n" + "=" * 60)
        print("âœ… PIPELINE TERMINÃ‰E AVEC SUCCÃˆS")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ERREUR DANS LA PIPELINE: {str(e)}")
        raise

def main():
    """Point d'entrÃ©e principal avec arguments en ligne de commande"""
    parser = argparse.ArgumentParser(description="Pipeline de vectorisation de documents")
    parser.add_argument("--chunk-size", type=int, default=1000, 
                       help="Taille maximale des chunks en caractÃ¨res (dÃ©faut: 1000)")
    parser.add_argument("--overlap", type=int, default=200,
                       help="Chevauchement entre chunks en caractÃ¨res (dÃ©faut: 200)")
    parser.add_argument("--clear-db", action="store_true",
                       help="Vider la base de donnÃ©es avant l'insertion")
    parser.add_argument("--stats-only", action="store_true",
                       help="Afficher uniquement les statistiques de la DB")
    
    args = parser.parse_args()
    
    if args.stats_only:
        print("ğŸ“Š Statistiques de la base de donnÃ©es:")
        get_collection_stats()
        return
    
    run_pipeline(
        chunk_size=args.chunk_size,
        overlap=args.overlap,
        clear_db=args.clear_db
    )

if __name__ == "__main__":
    main()